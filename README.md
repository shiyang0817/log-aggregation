# log-aggregation

quite a number of customers have their critical systems deployed on-premise, especially for those customers who are sensitive towards data security.
however, logs collected from those on-prem systems usually have large volumes with values dispered between those countless records are less sensitive, and when it comes to cross geo-region aggregation scenario, it is necessary to store those logs on cloud to achieve the aggregated anaylsis, since cloud offers a cross region integrated platform with high scalability and durability.

this doc offers the log aggregation solution leveraging on aws cloud services. logs are generated by different geo-regions, these logs will be collected to the nearest aws regions first, and sync to a central region for aggregation analysis.

1. IDC logs transfered to nearest aws region
   1.1 first, a client agent needs to be installed on customers IDC enviroment. the agent is named as Kinesis Agent
   Please refer to the below link for further installation guidance:
   
   https://docs.aws.amazon.com/streams/latest/dev/writing-with-agents.html
   
   a sample of agent.json:ã€€
   {
      "kinesis.endpoint": "kinesis.ap-southeast-1.amazonaws.com", 
      "flows": [
                 {
                   "filePattern": "/tmp/app.log*",
                   "kinesisStream": "jan5-kds-sg"
                 }
       ]
    }
    
    1.2 Kinesis Data Streams + Kinesis Data Firhose pipeline
    the log data will be transferred through the KDS + KDF pipepline and finally stored in s3 bucket.
    Please refer to the below link for further setup guidance:
    
    https://docs.aws.amazon.com/firehose/latest/dev/writing-with-kinesis-streams.html
    
    
2. logs stored in different aws regions aggregation
   the aggregation of logs stored in different regions are achieved leveraging on aws s3 cross region replication feature.
   please refer to the below link for further guidance:
   
   https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/userguide/replication-walkthrough1.html

3. analysis those logs through aws opensearch
   the logs stored in s3 will be ingested into opensearch service domain for further analysis.
   please refer to the lambda function explanation as the below link:
   
   https://docs.aws.amazon.com/opensearch-service/latest/developerguide/integrations.html#integrations-s3-lambda
   
   and the docs link below for detail packaging guidance:
   
   https://docs.aws.amazon.com/lambda/latest/dg/python-package.html#python-package-create-package-no-dependency
   
   the lambda function needs to be authenticated by opensearch cluster. the authentication role mapping guidance is as below:
   
   https://docs.aws.amazon.com/opensearch-service/latest/developerguide/fgac.html#fgac-mapping
   
